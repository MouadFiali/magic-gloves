{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook extends our initial project on translating sign language. The focus here is on assessing the robustness of our model against potential sensor malfunctions. We simulate malfunctions by intentionally altering sensor data and evaluate the model's performance across various sensor combinations. This exercise aims to understand how sensor failures might impact the accuracy and reliability of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Initial Model Development\n",
    "This section revisits the steps taken in our previous notebook, including data preprocessing, model building, and initial training. These foundational steps provide the context for our current focus on evaluating model robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "(1791, 441)\n",
      "WARNING:tensorflow:From c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mouad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "45/45 [==============================] - 3s 11ms/step - loss: 0.9792 - accuracy: 0.6969 - val_loss: 1.1125 - val_accuracy: 0.5335\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.9211 - val_loss: 0.4160 - val_accuracy: 0.9665\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9860 - val_loss: 0.1582 - val_accuracy: 0.9944\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9909 - val_loss: 0.0447 - val_accuracy: 0.9944\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9958 - val_loss: 0.0239 - val_accuracy: 0.9972\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9937 - val_loss: 0.0354 - val_accuracy: 0.9916\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9951 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9986 - val_loss: 0.0059 - val_accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9972\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9979 - val_loss: 0.0143 - val_accuracy: 0.9972\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0077 - val_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0075 - val_accuracy: 0.9972\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0242 - val_accuracy: 0.9944\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0147 - val_accuracy: 0.9944\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 5.3087e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 6.8033e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9972\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 2.8477e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 3.3488e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3904e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.7083e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0038 - val_accuracy: 0.9972\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9972\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 2.0973e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.2584e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 8.2296e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0308 - val_accuracy: 0.9888\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.4499e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 4.9520e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 1.8556e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 1.1089e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0071 - val_accuracy: 0.9972\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9972 - val_loss: 0.1273 - val_accuracy: 0.9637\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0029 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19b35ff8ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import SimpleRNN, Bidirectional, BatchNormalization\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "df_1 = pd.read_csv('../dataset/sensor_data_badr.csv')\n",
    "df_2 = pd.read_csv('../dataset/sensor_data_mouad.csv')\n",
    "df_3 = pd.read_csv('../dataset/sensor_data_ismail.csv')\n",
    "# Concatenate the three dataframes\n",
    "df = pd.concat([df_1, df_2, df_3], ignore_index=True)\n",
    "\n",
    "# number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# Convert all feature columns to numeric and set non-convertible values to NaN\n",
    "for col in df.columns[:-1]:  # Excluding the last column\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Removing rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1].values  # All columns except the last one\n",
    "y = df.iloc[:, -1].values   # Only the last column\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape X to fit the RNN model (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Encode the labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Define the RNN model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Bidirectional(SimpleRNN(30, activation='relu', return_sequences=True), input_shape=(X.shape[1], X.shape[2])))\n",
    "model_rnn.add(BatchNormalization())\n",
    "model_rnn.add(SimpleRNN(32, activation='relu'))\n",
    "model_rnn.add(Dropout(0.3))\n",
    "model_rnn.add(Dense(16, activation='relu'))\n",
    "model_rnn.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical_crossentropy loss function\n",
    "model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add EarlyStopping as a callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_rnn.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Malfunction Simulation\n",
    "We simulate sensor malfunctions by intentionally setting the data for specific sensors to zero. This approach helps us to understand how the model performs when certain sensors fail or provide incorrect readings, a scenario that could occur in real-world usage.\n",
    "\n",
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malfunction(X, sensor, value):\n",
    "    if sensor.startswith('Position') or sensor.startswith('Orientation'):\n",
    "        for col in df.columns:\n",
    "            # Get the column starting with the sensor name and has the hand name in it (left or right)\n",
    "            hand = sensor.split('-')[1]\n",
    "            if col.startswith(sensor.split('-')[0]) and hand in col:\n",
    "                X[:, :, df.columns.get_loc(col)] = value\n",
    "    else:\n",
    "        for col in df.columns:\n",
    "            if col.startswith(sensor):\n",
    "                X[:, :, df.columns.get_loc(col)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    y_pred = model_rnn.predict(X)\n",
    "    # Convert predictions to classes\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation on Malfunctioned Data\n",
    "In this section, we loop over various combinations of malfunctioning sensors and evaluate the model's performance. This process involves adjusting the data to simulate different malfunction scenarios and then computing key metrics like accuracy, precision, recall, and F1-score for each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 16383\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "sensors = []\n",
    "for i in range(1, 6):\n",
    "    sensors.append(f'Flex-Left-{i}')\n",
    "    sensors.append(f'Flex-Right-{i}')\n",
    "sensors.append(f'Position-Left')\n",
    "sensors.append(f'Position-Right')\n",
    "sensors.append(f'Orientation-Left')\n",
    "sensors.append(f'Orientation-Right')\n",
    "\n",
    "combinations = []\n",
    "for i in range(1, len(sensors) + 1):\n",
    "    # Get all combinations of sensors\n",
    "    combinations += list(itertools.combinations(sensors, i))\n",
    "\n",
    "print(f\"Number of combinations: {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to try combinations of sensor values by destroying other sensors (try all combinations)\n",
    "# Meaning that we will first try to remove 1 sensor, then 2 sensors (with all possible combinations), then 3 sensors, and so on\n",
    "# The function will return the accuracy, precision, recall, and F1-score for each combination sorted by accuracy\n",
    "import itertools\n",
    "\n",
    "\n",
    "def try_combinations(X, y_test):\n",
    "    # Get the names of the sensors\n",
    "    sensors = []\n",
    "    for i in range(1, 6):\n",
    "        sensors.append(f'Flex-Left-{i}')\n",
    "        sensors.append(f'Flex-Right-{i}')\n",
    "    sensors.append(f'Position-Left')\n",
    "    sensors.append(f'Position-Right')\n",
    "    sensors.append(f'Orientation-Left')\n",
    "    sensors.append(f'Orientation-Right')\n",
    "    \n",
    "    # Create a list to store the results\n",
    "    results = []\n",
    "    # Loop over the sensors\n",
    "    for i in range(1, len(sensors) + 1):\n",
    "        # Get all combinations of sensors\n",
    "        combinations = list(itertools.combinations(sensors, i))\n",
    "        # Loop over the combinations\n",
    "        for combination in combinations:\n",
    "            # Create a copy of the test set\n",
    "            X_test_copy = X.copy()\n",
    "            # Destroy the sensors in the combination\n",
    "            for sensor in combination:\n",
    "                malfunction(X_test_copy, sensor, 0)\n",
    "            # Predict the labels\n",
    "            y_pred = model_rnn.predict(X_test_copy)\n",
    "            # Convert predictions to classes\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            y_test_classes = np.argmax(y_test, axis=1)\n",
    "            # Calculate the accuracy\n",
    "            accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "            # Calculate precision, recall, and F1-score\n",
    "            precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "            recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "            f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "            # Append the results to the list\n",
    "            results.append([combination, accuracy, precision, recall, f1])\n",
    "            print(\"************************************\")\n",
    "            print(f\"Combination {combination}:\")\n",
    "            print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    # Sort the results by accuracy\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = try_combinations(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Storage and Comprehensive Analysis\n",
    "The results of our evaluations are stored for detailed analysis. This analysis aims to identify patterns in the model's performance degradation related to specific sensor failures, providing insights into the model's robustness and areas for improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "df_results = pd.DataFrame(results, columns=['Combination', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination: ('Flex-Left-1',)\n",
      "Accuracy: 100.00%\n",
      "Combination: ('Flex-Left-1', 'Flex-Left-4')\n",
      "Accuracy: 100.00%\n",
      "Combination: ('Flex-Right-2', 'Flex-Right-3', 'Flex-Left-4')\n",
      "Accuracy: 100.00%\n",
      "Combination: ('Flex-Left-1', 'Flex-Right-2', 'Flex-Right-3', 'Flex-Left-4')\n",
      "Accuracy: 100.00%\n",
      "Combination: ('Flex-Left-1', 'Flex-Right-2', 'Flex-Right-3', 'Flex-Left-4', 'Flex-Right-5')\n",
      "Accuracy: 99.72%\n",
      "Combination: ('Flex-Left-1', 'Flex-Right-1', 'Flex-Right-2', 'Flex-Right-3', 'Position-Left', 'Position-Right')\n",
      "Accuracy: 98.88%\n",
      "Number of sensors: 6\n"
     ]
    }
   ],
   "source": [
    "# Get the combination with accuracy > 0.95 and print its combination and accuracy\n",
    "max_combination = 0\n",
    "for result in results:\n",
    "    if result[1] > 0.95 and len(result[0]) > max_combination:\n",
    "        max_combination = len(result[0])\n",
    "        print(f\"Combination: {result[0]}\")\n",
    "        print(f\"Accuracy: {result[1] * 100:.2f}%\")\n",
    "\n",
    "print(f\"Number of sensors: {max_combination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Our investigation into the model's robustness against sensor malfunctions has provided valuable insights. The results indicate how sensor failures impact the overall performance, highlighting the need for fault-tolerant designs in practical applications. Furthermore, through this evaluation, we have gained a clearer understanding of the relative importance of each sensor in our device. We identified certain sensors that do not significantly contribute to the model's predictive ability. This knowledge is invaluable, as it allows us to optimize our design by focusing on the most critical sensors and considering the removal or replacement of sensors that add minimal value. This streamlining could lead to more efficient and cost-effective designs without compromising the functionality and accuracy of our sign language translation tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
