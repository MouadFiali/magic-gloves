{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook investigates the generalization capability of our AI model in translating sign language. We train the model on datasets from different team members and then evaluate its performance on unseen data from other members. This approach allows us to understand the model's effectiveness in handling data variations and its reliability in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Preprocessing Functions\n",
    "We define two key functions: `train_rnn_model` for training the RNN model on selected datasets and `preprocess_test_data` for preprocessing test data. These functions streamline the process of retraining the model on different datasets and preparing various test datasets for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import SimpleRNN, Bidirectional, BatchNormalization\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def train_rnn_model(*dataset_paths):\n",
    "\n",
    "     # Load and concatenate the datasets\n",
    "    dfs = [pd.read_csv(path) for path in dataset_paths]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # number of rows and columns\n",
    "    print(df.shape)\n",
    "\n",
    "    # Convert all feature columns to numeric and set non-convertible values to NaN\n",
    "    for col in df.columns[:-1]:  # Excluding the last column\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Removing rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df.iloc[:, :-1].values  # All columns except the last one\n",
    "    y = df.iloc[:, -1].values   # Only the last column\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Reshape X to fit the RNN model (samples, time steps, features)\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "    # Encode the labels\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    # Define the RNN model\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(Bidirectional(SimpleRNN(30, activation='relu', return_sequences=True), input_shape=(X.shape[1], X.shape[2])))\n",
    "    model_rnn.add(BatchNormalization())\n",
    "    model_rnn.add(SimpleRNN(32, activation='relu'))\n",
    "    model_rnn.add(Dropout(0.3))\n",
    "    model_rnn.add(Dense(16, activation='relu'))\n",
    "    model_rnn.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compile the model with categorical_crossentropy loss function\n",
    "    model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Add EarlyStopping as a callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model_rnn.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    # Save the model\n",
    "    model_rnn.save('rnn_model.h5')\n",
    "    # Save the scaler to use it in predict.py and scale the realtime data\n",
    "    joblib.dump(scaler, 'rnn_scaler.joblib')\n",
    "\n",
    "    return model_rnn, scaler, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(df_test, scaler, encoder):\n",
    "    df_test.dropna(inplace=True)\n",
    "    X_test = df_test.iloc[:, :-1].values\n",
    "    y_test = df_test.iloc[:, -1].values\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "    y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "    return X_test, y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_rnn, X, y_test):\n",
    "    y_pred = model_rnn.predict(X)\n",
    "    # Convert predictions to classes\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation on Unseen Data\n",
    "## First Test\n",
    "In this section, we evaluate the model's performance on data from Mouad, who was not included in the initial training set. This test aims to assess the model's ability to generalize from the training data to new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1191, 441)\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "30/30 [==============================] - 3s 18ms/step - loss: 1.2122 - accuracy: 0.5284 - val_loss: 1.3548 - val_accuracy: 0.4790\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.8319 - val_loss: 0.9268 - val_accuracy: 0.6849\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.9401 - val_loss: 0.5192 - val_accuracy: 0.8866\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9863 - val_loss: 0.2303 - val_accuracy: 0.9874\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9905 - val_loss: 0.0821 - val_accuracy: 0.9958\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9958 - val_loss: 0.0449 - val_accuracy: 0.9958\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9979 - val_loss: 0.0328 - val_accuracy: 0.9958\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9916 - val_loss: 0.0197 - val_accuracy: 0.9958\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9989 - val_loss: 0.0157 - val_accuracy: 0.9958\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9968 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0242 - val_accuracy: 0.9958\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9958\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 0.9958\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.0112 - val_accuracy: 0.9958\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9958\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9958\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9958\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9958\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0064 - val_accuracy: 0.9958\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9958\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0153 - val_accuracy: 0.9958\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0247 - val_accuracy: 0.9958\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 8.2625e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.7881e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9958\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0232 - val_accuracy: 0.9916\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9958\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9958\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 0.9958\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9958\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0133 - val_accuracy: 0.9958\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_rnn, scaler, encoder = train_rnn_model('../dataset/sensor_data_badr.csv', '../dataset/sensor_data_ismail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../dataset/sensor_data_mouad.csv')\n",
    "X_test_mouad, y_test_mouad_encoded = preprocess_test_data(df_test, scaler, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step\n",
      "Accuracy on the test set: 99.33%\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-score: 0.99\n"
     ]
    }
   ],
   "source": [
    "predict(model_rnn, X_test_mouad, y_test_mouad_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Test\n",
    "Following the first test, we retrain the model on a larger dataset including Mouad's data and then test it on data from Kamal, another member not previously included. This step is crucial for assessing how well the model adapts to new individuals and the potential impact of dataset quality on model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1791, 441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - 3s 13ms/step - loss: 1.1473 - accuracy: 0.5279 - val_loss: 1.4568 - val_accuracy: 0.4274\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.9092 - val_loss: 0.6938 - val_accuracy: 0.6983\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9797 - val_loss: 0.3887 - val_accuracy: 0.8296\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9881 - val_loss: 0.0737 - val_accuracy: 0.9916\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9923 - val_loss: 0.0246 - val_accuracy: 0.9972\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9944 - val_loss: 0.0116 - val_accuracy: 0.9972\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9972 - val_loss: 0.0063 - val_accuracy: 0.9972\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9958 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9972 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0026 - val_accuracy: 0.9972\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.2976 - val_accuracy: 0.9134\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0601 - val_accuracy: 0.9749\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0075 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0105 - val_accuracy: 0.9972\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9972\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.0093 - val_accuracy: 0.9972\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 9.4701e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 6.7546e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0329 - val_accuracy: 0.9944\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.6238e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 3.3920e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 2.6321e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.7073e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 9.8502e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 9.3515e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0210 - val_accuracy: 0.9972\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9860\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0103 - val_accuracy: 0.9972\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9972\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9972\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0132 - val_accuracy: 0.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_rnn, scaler, encoder = train_rnn_model('../dataset/sensor_data_badr.csv', '../dataset/sensor_data_mouad.csv', '../dataset/sensor_data_ismail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../dataset/sensor_data_kamal.csv')\n",
    "X_test_kamal, y_test_kamal_encoded = preprocess_test_data(df_test, scaler, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n",
      "Accuracy on the test set: 71.94%\n",
      "Precision: 0.83\n",
      "Recall: 0.72\n",
      "F1-score: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\ENSIMAG\\IA & IoT\\magic-gloves\\magic-gloves-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict(model_rnn, X_test_kamal, y_test_kamal_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The results from testing the model on unseen data highlight its capabilities and limitations in generalizing from the training dataset. While the model performed well on data from Mouad, the decreased accuracy observed with Kamal's data underscores the importance of dataset quality and diversity in training. These findings emphasize the need for comprehensive and varied training data to ensure the model's effectiveness across different individuals and sign language variations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
